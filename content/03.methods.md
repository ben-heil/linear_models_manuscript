## Methods

TODO outline sections


### Data
- From X, downloaded Y
- What are the tissue labels based on
- What are the sex labels based on
- Preprocessing/filtering (tpm norm, zero-one standardization, 
- Amount of data after filtering (X samples, Y labeled w/ tissue, Z labeled w/ sex)
- Label source (tissue and sex)

### Data splitting
- Studywise splitting (how is it done and why)
- Samplewise splitting (and cite some papers using samplewise?)

### Models used
- One sentence description of deep and three layer nets
- One sentence description of pytorchLR, sklearnLR, and why I used both

### Model training
- Early stopping, dropout (is this true for 3 layer?), loss, optimizers
- Loss weighting
- Gradient clipping
- Link to model configs dir for hyperparameters
- sklearn used all data, everything else used minibatch optimization
- Ensuring determinism in model training (setting seeds, pytorch magic)

### Binary classification?
Workflow

### Multitissue classification
- Mention this formulation is used for both the tissue and sex prediction
- Which tissues and why
- How is the data split with respect to the tissues
- Metric for performance

### Transfer learning
- Pretraining setup (train on different studies with same labels)
- Data splitting details

### Pretraining
- Pretraining setup (imputation)
- How much data is used for pretraining?
- Matching initializations for pretrained and non-pretrained networks

### Visualizing expression compendium
- Extracted 1000 expression samples at random
- Plotted via UMAP and PCA

### Hardware requirements
OS version, CPU/GPU model, RAM, vRAM, time to run (wall)
